\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Case Study: Bayesian Linear Regression}{19}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Preliminaries}{19}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Model Definition}{19}{subsection.4.1.1}}
\newlabel{eq:likelihood}{{4.1}{19}{Model Definition}{equation.4.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Analytical Update Equations}{20}{subsection.4.1.2}}
\citation{Bishop:2006}
\citation{Bishop:2006}
\newlabel{eq:exact_update_one}{{4.9}{21}{Analytical Update Equations}{equation.4.1.9}{}}
\newlabel{eq:exact_update_two}{{4.10}{21}{Analytical Update Equations}{equation.4.1.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Gradient of Local Free Energy}{21}{subsection.4.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}Assessing Performance}{22}{subsection.4.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}Data Generation}{23}{subsection.4.1.5}}
\newlabel{eq:data-gen}{{4.18}{23}{Data Generation}{equation.4.1.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Datapoint Level DP-PVI}{23}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}DP-SGD}{23}{subsection.4.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces  Data-point level DP-PVI implemented using DP-SGD. First plot outlines evolution of the natural parameters stored at the central parameter server as the number of iterations increases. The $\altmathcal  {KL}$ divergence between $q(\theta )$ and the true posterior is also plotted (middle sub-plot), as is the privacy guarantee, $\epsilon $, with $\delta = 10^{-5}$ fixed (bottom sub-plot). Parameters used: $\theta =2$, $\sigma _e=0.5$, $\mu _\theta = 0$, $\sigma _\theta = 5$. Learning rate $\alpha = 10^{-5}$, $L = 1$, $C=10$, $\sigma =1$. $5$ workers with $\rho = 10$ points per worker. $50$ iterations of DP-SGD performed locally for one server update. \relax }}{24}{figure.caption.8}}
\newlabel{fig:results-dpsgd}{{4.1}{24}{Data-point level DP-PVI implemented using DP-SGD. First plot outlines evolution of the natural parameters stored at the central parameter server as the number of iterations increases. The $\altmathcal {KL}$ divergence between $q(\theta )$ and the true posterior is also plotted (middle sub-plot), as is the privacy guarantee, $\epsilon $, with $\delta = 10^{-5}$ fixed (bottom sub-plot). Parameters used: $\theta =2$, $\sigma _e=0.5$, $\mu _\theta = 0$, $\sigma _\theta = 5$. Learning rate $\alpha = 10^{-5}$, $L = 1$, $C=10$, $\sigma =1$. $5$ workers with $\rho = 10$ points per worker. $50$ iterations of DP-SGD performed locally for one server update. \relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces  Privacy cost for different sampling probabilities, $q = L / N$, as a function of the number of epochs assuming a mechanism which sub-samples from each dataset. An epoch is defined as the mechanism having been run processed $\frac  {1}{q}$ times i.e. $N$ data-points having been visited. \relax }}{25}{figure.caption.9}}
\newlabel{fig:results-ma}{{4.2}{25}{Privacy cost for different sampling probabilities, $q = L / N$, as a function of the number of epochs assuming a mechanism which sub-samples from each dataset. An epoch is defined as the mechanism having been run processed $\frac {1}{q}$ times i.e. $N$ data-points having been visited. \relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Analytical Updates}{25}{subsection.4.2.2}}
\newlabel{eq:local-pres}{{4.21}{25}{Analytical Updates}{equation.4.2.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Simulation on introduced bias on titled posterior calculation. Prior, $p(\theta ) = \altmathcal  {N}(0, 5)$ with $\sigma _e = 0.5$, $10$ data-points spaced uniformly in $[-1, 1]$. $N=10000$ draws of differential privacy corrupting noise (with $\sigma =1$) used to produce empirical distributions. Clipped neglected. \relax }}{26}{figure.caption.10}}
\newlabel{fig:results-local-bias}{{4.3}{26}{Simulation on introduced bias on titled posterior calculation. Prior, $p(\theta ) = \altmathcal {N}(0, 5)$ with $\sigma _e = 0.5$, $10$ data-points spaced uniformly in $[-1, 1]$. $N=10000$ draws of differential privacy corrupting noise (with $\sigma =1$) used to produce empirical distributions. Clipped neglected. \relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces  Results obtained with data-point level differential privacy with $\epsilon _{\text  {max}} = 10$ (i.e. termination after $\epsilon $ exceeds this value). Top left plot shows ratio between the true precision and obtained precision as a function of $\theta $, averaged over the last ten iterations of the DP-PVI algorithm. Top right plot shows $\altmathcal  {KL}(q||p)$ (again averaged over the ten last iterations) as a function of $\theta $. Bottom left plots show the mean, median and chosen percentiles of this averaged $\altmathcal  {KL}$ divergence as a function of $C$ (across the $50$ different values of $\theta $) and the bottom right plot shows the corresponding standard deviation. $50$ random seeds used for each clipping bound value with each random seed corresponding to a specific $\theta $ sampled from the prior distribution, $p(\theta ) = \altmathcal  {N}(0, 5)$ and specific draw of corrupting noise. $\sigma _e = 0.5$, $\sigma =5$, $\alpha =0.1$ with $M=20$ workers and $\rho = 10$ data-points per worker. \relax }}{28}{figure.caption.11}}
\newlabel{fig:results-local-ana}{{4.4}{28}{Results obtained with data-point level differential privacy with $\epsilon _{\text {max}} = 10$ (i.e. termination after $\epsilon $ exceeds this value). Top left plot shows ratio between the true precision and obtained precision as a function of $\theta $, averaged over the last ten iterations of the DP-PVI algorithm. Top right plot shows $\altmathcal {KL}(q||p)$ (again averaged over the ten last iterations) as a function of $\theta $. Bottom left plots show the mean, median and chosen percentiles of this averaged $\altmathcal {KL}$ divergence as a function of $C$ (across the $50$ different values of $\theta $) and the bottom right plot shows the corresponding standard deviation. $50$ random seeds used for each clipping bound value with each random seed corresponding to a specific $\theta $ sampled from the prior distribution, $p(\theta ) = \altmathcal {N}(0, 5)$ and specific draw of corrupting noise. $\sigma _e = 0.5$, $\sigma =5$, $\alpha =0.1$ with $M=20$ workers and $\rho = 10$ data-points per worker. \relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces  Typical posteriors obtained using the data-point level DP-PVI algorithm with analytical clipped updates. Produced with $C=2$, $\alpha =0.1$, $M=20$ workers with $\rho = 10$ data-points per worker. Averaged variational parameters across the final ten iterations used to produce above plot. \relax }}{29}{figure.caption.12}}
\newlabel{fig:results-local-ana-post}{{4.5}{29}{Typical posteriors obtained using the data-point level DP-PVI algorithm with analytical clipped updates. Produced with $C=2$, $\alpha =0.1$, $M=20$ workers with $\rho = 10$ data-points per worker. Averaged variational parameters across the final ten iterations used to produce above plot. \relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Hydrid Scheme}{30}{subsection.4.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces  Results obtained with data-point level differential privacy applied \textbf  {without noise} when run for the same number of iterations as Fig. \ref  {fig:results-local-ana}. Top left plot shows ratio between the true precision and obtained precision as a function of $\theta $, averaged over the last ten iterations of the DP-PVI algorithm. Top right plot shows the $\altmathcal  {KL}(q||p)$ (again averaged over the ten last iterations) as a function of $\theta $. Bottom left plots show the mean, median and chosen percentiles of this averaged $\altmathcal  {KL}$ divergence as a function of $C$ (across the $50$ different values of $\theta $) and the bottom right plot shows the corresponding standard deviation. $50$ random seeds used for each clipping bound value with each random seed corresponding to a specific $\theta $ sampled from the prior distribution, $p(\theta ) = \altmathcal  {N}(0, 5)$ and specific draw of corrupting noise. $\sigma _e = 0.5$, $\alpha =0.1$ with $M=20$ workers and $10$ data-points per worker. \relax }}{31}{figure.caption.13}}
\newlabel{fig:results-noiseless-local-ana}{{4.6}{31}{Results obtained with data-point level differential privacy applied \textbf {without noise} when run for the same number of iterations as Fig. \ref {fig:results-local-ana}. Top left plot shows ratio between the true precision and obtained precision as a function of $\theta $, averaged over the last ten iterations of the DP-PVI algorithm. Top right plot shows the $\altmathcal {KL}(q||p)$ (again averaged over the ten last iterations) as a function of $\theta $. Bottom left plots show the mean, median and chosen percentiles of this averaged $\altmathcal {KL}$ divergence as a function of $C$ (across the $50$ different values of $\theta $) and the bottom right plot shows the corresponding standard deviation. $50$ random seeds used for each clipping bound value with each random seed corresponding to a specific $\theta $ sampled from the prior distribution, $p(\theta ) = \altmathcal {N}(0, 5)$ and specific draw of corrupting noise. $\sigma _e = 0.5$, $\alpha =0.1$ with $M=20$ workers and $10$ data-points per worker. \relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces  Typical posteriors obtained using the \textbf  {noiseless} data-point level DP-PVI algorithm with analytical clipped updates. Produced with $C=2$, $\alpha =0.1$, $M=20$ workers with $10$ data-points per worker. Averaged variational parameters across the final ten iterations used to produce above plots.\relax }}{32}{figure.caption.14}}
\newlabel{fig:results-noiseless-typical-post}{{4.7}{32}{Typical posteriors obtained using the \textbf {noiseless} data-point level DP-PVI algorithm with analytical clipped updates. Produced with $C=2$, $\alpha =0.1$, $M=20$ workers with $10$ data-points per worker. Averaged variational parameters across the final ten iterations used to produce above plots.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Dataset Level DP-PVI}{33}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Analytical Updates}{33}{subsection.4.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Robustness Study}{34}{subsection.4.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces  Results obtained with dataset level differential privacy applied with $\epsilon _\text  {max} = 10$ (termination after $\epsilon $ exceeds this value). Top left plot shows ratio between the true precision and obtained precision as a function of $\theta $, averaged over the last ten iterations of the DP-PVI algorithm. Top right plot shows $\altmathcal  {KL}(q||p)$ (again averaged over the ten last iterations) as a function of $\theta $ for chosen settings of $C$ and $\alpha $. Bottom left plots show the mean, median and chosen percentiles of this averaged $\altmathcal  {KL}$ divergence for different algorithm settings (across the $50$ different values of $\theta $) and the bottom right plot shows the corresponding standard deviation. $50$ random seeds used for each clipping bound value; each random seed corresponding to a specific $\theta $ sampled from the prior distribution, $p(\theta ) = \altmathcal  {N}(0, 5)$, a specific draw of corrupting noise and a value of $\sigma _e$ sampled from $\altmathcal  {U}(0.5, 2)$. $M=20$ workers and $\rho = 10$ data-points per worker. $\sigma =5$. \relax }}{35}{figure.caption.15}}
\newlabel{fig:results-dataset-results}{{4.8}{35}{Results obtained with dataset level differential privacy applied with $\epsilon _\text {max} = 10$ (termination after $\epsilon $ exceeds this value). Top left plot shows ratio between the true precision and obtained precision as a function of $\theta $, averaged over the last ten iterations of the DP-PVI algorithm. Top right plot shows $\altmathcal {KL}(q||p)$ (again averaged over the ten last iterations) as a function of $\theta $ for chosen settings of $C$ and $\alpha $. Bottom left plots show the mean, median and chosen percentiles of this averaged $\altmathcal {KL}$ divergence for different algorithm settings (across the $50$ different values of $\theta $) and the bottom right plot shows the corresponding standard deviation. $50$ random seeds used for each clipping bound value; each random seed corresponding to a specific $\theta $ sampled from the prior distribution, $p(\theta ) = \altmathcal {N}(0, 5)$, a specific draw of corrupting noise and a value of $\sigma _e$ sampled from $\altmathcal {U}(0.5, 2)$. $M=20$ workers and $\rho = 10$ data-points per worker. $\sigma =5$. \relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces  Typical posteriors obtained the dataset level DP-PVI algorithm. Produced with $C=5$, $\alpha =0.1$, $M=20$ workers with $\rho = 10$ data-points per worker. Variational distribution parameters averaged across the final ten iterations to produce plots. \relax }}{36}{figure.caption.16}}
\newlabel{fig:results-dataset-typical-post}{{4.9}{36}{Typical posteriors obtained the dataset level DP-PVI algorithm. Produced with $C=5$, $\alpha =0.1$, $M=20$ workers with $\rho = 10$ data-points per worker. Variational distribution parameters averaged across the final ten iterations to produce plots. \relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces  Results obtained with the dataset level DP-PVI algorithm \textbf  {without adding noise}. The number of iterations performed is increased to $1000$ instead of terminating after the privacy budget is consumed. Top left plot shows ratio between the true precision and obtained precision as a function of $\theta $, averaged over the last ten iterations of the DP-PVI algorithm. Top right plot shows the $\altmathcal  {KL}(q||p)$ (again averaged over the ten last iterations) as a function of $\theta $ for chosen settings of $C$ and $\alpha $. Bottom left plots show the mean, median and chosen percentiles of this averaged $\altmathcal  {KL}$ divergence for different algorithm settings (across the $50$ different values of $\theta $) and the bottom right plot shows the corresponding standard deviation. $50$ random seeds used for each clipping bound value; each random seed corresponding to a specific $\theta $ sampled from the prior distribution, $p(\theta ) = \altmathcal  {N}(0, 5)$, a specific draw of corrupting noise and a value of $\sigma _e$ sampled from $\altmathcal  {U}(0.5, 2)$. $M=20$ workers and $\rho = 10$ data-points per worker. $\sigma =5$. \relax }}{37}{figure.caption.17}}
\newlabel{fig:results-dataset-noiseless}{{4.10}{37}{Results obtained with the dataset level DP-PVI algorithm \textbf {without adding noise}. The number of iterations performed is increased to $1000$ instead of terminating after the privacy budget is consumed. Top left plot shows ratio between the true precision and obtained precision as a function of $\theta $, averaged over the last ten iterations of the DP-PVI algorithm. Top right plot shows the $\altmathcal {KL}(q||p)$ (again averaged over the ten last iterations) as a function of $\theta $ for chosen settings of $C$ and $\alpha $. Bottom left plots show the mean, median and chosen percentiles of this averaged $\altmathcal {KL}$ divergence for different algorithm settings (across the $50$ different values of $\theta $) and the bottom right plot shows the corresponding standard deviation. $50$ random seeds used for each clipping bound value; each random seed corresponding to a specific $\theta $ sampled from the prior distribution, $p(\theta ) = \altmathcal {N}(0, 5)$, a specific draw of corrupting noise and a value of $\sigma _e$ sampled from $\altmathcal {U}(0.5, 2)$. $M=20$ workers and $\rho = 10$ data-points per worker. $\sigma =5$. \relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces  Training curves showing the evolution of natural parameters as the number of iterations (performed at the parameter server) increases for random seeds which resulted in good approximate posteriors. Dashed lines correspond to non-private values. $M=20$ clients, $\rho =10$ points per worker. $\epsilon \simeq 10, \delta = 10^{-5}$. Plot title values refer to values of $(C, \alpha )$. \relax }}{38}{figure.caption.18}}
\newlabel{fig:results-dataset-success}{{4.11}{38}{Training curves showing the evolution of natural parameters as the number of iterations (performed at the parameter server) increases for random seeds which resulted in good approximate posteriors. Dashed lines correspond to non-private values. $M=20$ clients, $\rho =10$ points per worker. $\epsilon \simeq 10, \delta = 10^{-5}$. Plot title values refer to values of $(C, \alpha )$. \relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces  Training curves showing the evolution of natural parameters as the number of iterations (performed at the parameter server) increases for random seeds which resulted in poor approximate posteriors. Dashed lines correspond to non-private values. $M=20$ clients, $\rho =10$ points per worker. $\epsilon \simeq 10, \delta = 10^{-5}$. Sub-plot titles refer to values of $(C, \alpha )$. \relax }}{39}{figure.caption.19}}
\newlabel{fig:results-dataset-failure}{{4.12}{39}{Training curves showing the evolution of natural parameters as the number of iterations (performed at the parameter server) increases for random seeds which resulted in poor approximate posteriors. Dashed lines correspond to non-private values. $M=20$ clients, $\rho =10$ points per worker. $\epsilon \simeq 10, \delta = 10^{-5}$. Sub-plot titles refer to values of $(C, \alpha )$. \relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces  Resulted obtained when varying $\rho $ and $M$ while fixing $\alpha = 0.1$ and $C = 0.5\rho $, in order to investigate how appropriate these parameter settings are across different datasets. $50$ random seeds, each corresponding to a value of $\theta $ sampled from $\altmathcal  {N}(0, 5)$ and $\sigma _e$ sampled from $\altmathcal  {U}(0.5, 2)$ and the corrupting noise sequence. In the left plot, $\rho = 10$ is fixed whilst $M$ varies. The right plot corresponds to $M=20$ being fixed whilst $\rho $ varies. $\altmathcal  {KL}$ divergences are averaged across the final ten iterations for each random seed, and the mean, median and values of chosen percentiles (across the random seeds) are plotted. \relax }}{40}{figure.caption.20}}
\newlabel{fig:results-dataset-robust}{{4.13}{40}{Resulted obtained when varying $\rho $ and $M$ while fixing $\alpha = 0.1$ and $C = 0.5\rho $, in order to investigate how appropriate these parameter settings are across different datasets. $50$ random seeds, each corresponding to a value of $\theta $ sampled from $\altmathcal {N}(0, 5)$ and $\sigma _e$ sampled from $\altmathcal {U}(0.5, 2)$ and the corrupting noise sequence. In the left plot, $\rho = 10$ is fixed whilst $M$ varies. The right plot corresponds to $M=20$ being fixed whilst $\rho $ varies. $\altmathcal {KL}$ divergences are averaged across the final ten iterations for each random seed, and the mean, median and values of chosen percentiles (across the random seeds) are plotted. \relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces  Typical posteriors for different values of $\rho $ obtained the dataset level DP-PVI algorithm. Produced with $C=0.5\rho $, $\alpha =0.1$, $M=20$ workers. $\altmathcal  {KL}$ divergences reported are averaged across the final ten iterations, and the mean values of $\eta _1$ and $\eta _2$ are used to plot the approximate posteriors shown. \relax }}{41}{figure.caption.21}}
\newlabel{fig:results-dataset-post-rob}{{4.14}{41}{Typical posteriors for different values of $\rho $ obtained the dataset level DP-PVI algorithm. Produced with $C=0.5\rho $, $\alpha =0.1$, $M=20$ workers. $\altmathcal {KL}$ divergences reported are averaged across the final ten iterations, and the mean values of $\eta _1$ and $\eta _2$ are used to plot the approximate posteriors shown. \relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Validity of Local Clipping}{42}{subsection.4.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.15}{\ignorespaces  Probability of local precision clipping occurring at the start of the dataset level DP-PVI algorithm (left sub-plot) and when close to convergence (right sub-plot) for different hyper-parameter settings. Parameters used in experiments are consistent with those elsewhere in the report. Left sub-plot: $\sigma = 5$. Right sub-plot: $C=5, \sigma =5, \alpha = 0.1$. $\sigma _e = 2$, which is the worst case of values considered here.\relax }}{43}{figure.caption.22}}
\newlabel{fig:invalid-clipping}{{4.15}{43}{Probability of local precision clipping occurring at the start of the dataset level DP-PVI algorithm (left sub-plot) and when close to convergence (right sub-plot) for different hyper-parameter settings. Parameters used in experiments are consistent with those elsewhere in the report. Left sub-plot: $\sigma = 5$. Right sub-plot: $C=5, \sigma =5, \alpha = 0.1$. $\sigma _e = 2$, which is the worst case of values considered here.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.16}{\ignorespaces  Example dataset level DP-PVI run with local precision clipping removed. Produced with $M=20$ workers, $\rho = 10$ points per worker, $C=5$, $\alpha =0.1$ and $\sigma = 5$, which are the suggested settings used for experiments. $\theta =2$ and $\sigma _e = 2$. Additional iterations are run, vertical dashed line shows the number of iterations when $\epsilon \simeq 10$. Horizontal dashed lines refer to non-private parameter values. \relax }}{44}{figure.caption.23}}
\newlabel{fig:valid}{{4.16}{44}{Example dataset level DP-PVI run with local precision clipping removed. Produced with $M=20$ workers, $\rho = 10$ points per worker, $C=5$, $\alpha =0.1$ and $\sigma = 5$, which are the suggested settings used for experiments. $\theta =2$ and $\sigma _e = 2$. Additional iterations are run, vertical dashed line shows the number of iterations when $\epsilon \simeq 10$. Horizontal dashed lines refer to non-private parameter values. \relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.17}{\ignorespaces  Comparison of performance between appropriate settings for both the dataset and data-point level DP-PVI schemes. Produced with $C=0.5\rho = 5$ for the dataset level protection and $C=1$ for the data-point level protection. $\rho = 10$ points per worker, $M = 20$ workers with $\alpha = 0.1$. $\altmathcal  {KL}$ values reported are averaged across the final ten iterations. The DP noise level is fixed at $\sigma =5$.\relax }}{45}{figure.caption.24}}
\newlabel{fig:results-comp}{{4.17}{45}{Comparison of performance between appropriate settings for both the dataset and data-point level DP-PVI schemes. Produced with $C=0.5\rho = 5$ for the dataset level protection and $C=1$ for the data-point level protection. $\rho = 10$ points per worker, $M = 20$ workers with $\alpha = 0.1$. $\altmathcal {KL}$ values reported are averaged across the final ten iterations. The DP noise level is fixed at $\sigma =5$.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Comparison between Dataset and Datapoint DP-PVI}{45}{section.4.4}}
\@setckpt{Results/results}{
\setcounter{page}{46}
\setcounter{equation}{32}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{17}
\setcounter{table}{0}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{parentequation}{0}
\setcounter{Item}{6}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{32}
\setcounter{ALG@line}{13}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{3}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{NAT@ctr}{0}
\setcounter{currfiledepth}{0}
\setcounter{theorem}{0}
\setcounter{corollary}{0}
\setcounter{section@level}{1}
}
