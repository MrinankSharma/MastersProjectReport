\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Case Study: Bayesian Linear Regression}{17}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@LN{360}{20}
\@LN{361}{20}
\@LN{362}{20}
\@LN{363}{20}
\@LN{364}{20}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Preliminaries}{17}{section.4.1}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!40}{\leavevmode {\color {green!40}o}}\ Unsure how much detail I ought to give here}{17}{section*.17}}
\@LN{365}{20}
\@LN{366}{20}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Model Definition}{17}{subsection.4.1.1}}
\@LN{367}{20}
\@LN{368}{20}
\@LN{369}{20}
\@LN{370}{20}
\@LN{371}{20}
\@LN{372}{20}
\@LN{373}{20}
\@LN{374}{20}
\@LN{375}{20}
\@LN{376}{20}
\@LN{377}{20}
\@LN{378}{20}
\@LN{379}{20}
\@LN{380}{20}
\citation{Bishop:2006}
\@LN{381}{21}
\@LN{382}{21}
\@LN{383}{21}
\@LN{384}{21}
\@LN{385}{21}
\@LN{386}{21}
\@LN{387}{21}
\@LN{388}{21}
\@LN{389}{21}
\@LN{390}{21}
\@LN{391}{21}
\@LN{392}{21}
\@LN{393}{21}
\@LN{394}{21}
\@LN{395}{21}
\@LN{396}{21}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Analytical Update Equations}{18}{subsection.4.1.2}}
\@LN{397}{21}
\@LN{398}{21}
\@LN{399}{21}
\@LN{400}{21}
\@LN{401}{21}
\@LN{402}{21}
\@LN{403}{21}
\@LN{404}{21}
\newlabel{eq:exact_update_one}{{4.9}{18}{Analytical Update Equations}{equation.4.1.9}{}}
\@LN{405}{21}
\newlabel{eq:exact_update_two}{{4.10}{18}{Analytical Update Equations}{equation.4.1.10}{}}
\@LN{406}{21}
\@LN{407}{21}
\citation{Bishop:2006}
\@LN{408}{22}
\@LN{409}{22}
\@LN{410}{22}
\@LN{411}{22}
\@LN{412}{22}
\@LN{413}{22}
\@LN{414}{22}
\@LN{415}{22}
\@LN{416}{22}
\@LN{417}{22}
\@LN{418}{22}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Gradient of Local Free Energy}{19}{subsection.4.1.3}}
\@LN{419}{22}
\@LN{420}{22}
\@LN{421}{22}
\@LN{422}{22}
\@LN{423}{22}
\@LN{424}{22}
\@LN{425}{22}
\@LN{426}{22}
\@LN{427}{22}
\@LN{428}{22}
\@LN{429}{22}
\@LN{430}{22}
\@LN{431}{22}
\@LN{432}{22}
\@LN{433}{22}
\@LN{434}{22}
\@LN{435}{23}
\@LN{436}{23}
\@LN{437}{23}
\@LN{438}{23}
\@LN{439}{23}
\@LN{440}{23}
\@LN{441}{23}
\@LN{442}{23}
\@LN{443}{23}
\@LN{444}{23}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}Assessing Performance}{20}{subsection.4.1.4}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!40}{\leavevmode {\color {green!40}o}}\ We use KL blah blah blah to assess performance, is this good? no, comment on this etc}{20}{section*.18}}
\@LN{445}{23}
\@LN{446}{23}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Datapoint Level DP-PVI}{20}{section.4.2}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!40}{\leavevmode {\color {green!40}o}}\ Need to explain how the data is generated}{20}{section*.19}}
\@LN{447}{23}
\@LN{448}{23}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}DP-SGA}{20}{subsection.4.2.1}}
\@LN{449}{23}
\@LN{450}{23}
\@LN{451}{23}
\@LN{452}{23}
\@LN{453}{23}
\@LN{454}{23}
\@LN{455}{23}
\@LN{456}{23}
\@LN{457}{23}
\@LN{458}{23}
\@LN{459}{23}
\@LN{460}{23}
\@LN{461}{24}
\@LN{462}{24}
\@LN{463}{24}
\@LN{464}{24}
\@LN{465}{24}
\@LN{466}{24}
\@LN{467}{24}
\@LN{468}{24}
\@LN{469}{24}
\@LN{470}{24}
\@LN{471}{24}
\@LN{472}{24}
\@LN{473}{24}
\@LN{474}{24}
\@LN{475}{24}
\@LN{476}{24}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Analytical Updates}{21}{subsection.4.2.2}}
\@LN{477}{24}
\@LN{478}{24}
\@LN{479}{24}
\@LN{480}{24}
\newlabel{eq:local-pres}{{4.20}{21}{Analytical Updates}{equation.4.2.20}{}}
\@LN{481}{24}
\@LN{482}{24}
\@LN{483}{24}
\@LN{484}{24}
\@LN{485}{24}
\@LN{486}{24}
\@LN{487}{24}
\@LN{488}{24}
\@LN{489}{24}
\@LN{490}{24}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!40}{\leavevmode {\color {green!40}o}}\ estimates is probably not the right word for this}{21}{section*.22}}
\@LN{491}{24}
\@LN{492}{24}
\@LN{493}{24}
\@LN{494}{24}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces  Differentially Private SGA Results. First figure outlines evolution of the natural parameters stored at the central parameter server as the number of iterations increases. The $\altmathcal  {KL}$ divergence between $q(\theta )$ and the true posterior is also plotted (middle sub-plot), as is privacy guarantee, $\epsilon $, with $\delta = 10^{-5}$ fixed (bottom sub-plot). Parameters used: $\theta =2$, $\sigma _e=0.5$, $\mu _\theta = 0$, $\sigma _\theta = 5$, $\eta = 10^{-5}$, $L = 1$, $C=10$, $\sigma =1$. $5$ workers with $10$ points per worker. $50$ iterations of DP-SGA performed locally for one server update. \relax }}{22}{figure.caption.20}}
\newlabel{fig:results-dpsgd}{{4.1}{22}{Differentially Private SGA Results. First figure outlines evolution of the natural parameters stored at the central parameter server as the number of iterations increases. The $\altmathcal {KL}$ divergence between $q(\theta )$ and the true posterior is also plotted (middle sub-plot), as is privacy guarantee, $\epsilon $, with $\delta = 10^{-5}$ fixed (bottom sub-plot). Parameters used: $\theta =2$, $\sigma _e=0.5$, $\mu _\theta = 0$, $\sigma _\theta = 5$, $\eta = 10^{-5}$, $L = 1$, $C=10$, $\sigma =1$. $5$ workers with $10$ points per worker. $50$ iterations of DP-SGA performed locally for one server update. \relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces  Privacy cost for different sampling probabilities, $q = L / N$, as a function of the number of epochs assuming a mechanism which sub-samples from each dataset. An epoch is defined as the mechanism having been run processed $\frac  {1}{q}$ times i.e. $N$ data-points having been visited. \relax }}{23}{figure.caption.21}}
\newlabel{fig:results-ma}{{4.2}{23}{Privacy cost for different sampling probabilities, $q = L / N$, as a function of the number of epochs assuming a mechanism which sub-samples from each dataset. An epoch is defined as the mechanism having been run processed $\frac {1}{q}$ times i.e. $N$ data-points having been visited. \relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Simulation on introduced bias on titled posterior calculation. Prior, $p(\theta ) = \altmathcal  {N}(0, 5)$ with $\sigma _e = 0.5$, $10$ data-points spaced uniformly between in $[-1, 1]$. $N=10000$ draws of differential privacy corrupting noise (with $\sigma =1$) used to produce empirical distributions. Clipped neglected. \relax }}{24}{figure.caption.23}}
\newlabel{fig:results-local-bias}{{4.3}{24}{Simulation on introduced bias on titled posterior calculation. Prior, $p(\theta ) = \altmathcal {N}(0, 5)$ with $\sigma _e = 0.5$, $10$ data-points spaced uniformly between in $[-1, 1]$. $N=10000$ draws of differential privacy corrupting noise (with $\sigma =1$) used to produce empirical distributions. Clipped neglected. \relax }{figure.caption.23}{}}
\@LN{495}{27}
\@LN{496}{27}
\@LN{497}{27}
\@LN{498}{27}
\@LN{499}{27}
\@LN{500}{27}
\@LN{501}{27}
\@LN{502}{27}
\@LN{503}{27}
\@LN{504}{27}
\@LN{505}{27}
\@LN{506}{27}
\@LN{507}{28}
\@LN{508}{28}
\@LN{509}{28}
\@LN{510}{28}
\@LN{511}{28}
\@LN{512}{28}
\@LN{513}{28}
\@LN{514}{28}
\@LN{515}{28}
\@LN{516}{28}
\@LN{517}{28}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!40}{\leavevmode {\color {green!40}o}}\ Need to think/discuss this argument in more detail}{25}{section*.26}}
\@LN{518}{28}
\@LN{519}{28}
\@LN{520}{28}
\@LN{521}{28}
\@LN{522}{28}
\@LN{523}{28}
\@LN{524}{28}
\@LN{525}{28}
\@LN{526}{28}
\@LN{527}{28}
\@LN{528}{28}
\@LN{529}{28}
\@LN{530}{28}
\@LN{531}{28}
\@LN{532}{28}
\@LN{533}{28}
\@LN{534}{28}
\@LN{535}{28}
\@LN{536}{28}
\@LN{537}{28}
\@LN{538}{28}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces  Results obtained with data-point level differential privacy with $\epsilon _{\text  {max}} = 10$ (i.e. termination after $\epsilon $ exceeds this value). Top left plot shows ratio between the true precision and obtained precision as a function of $\theta $, averaged over the last ten iterations of the DP-PVI algorithm. Top right plot shows the $\altmathcal  {KL}(q||p)$ (again averaged over the ten last iterations) as a function of $\theta $. Bottom left plots show the mean, median and chosen percentiles of this averaged $\altmathcal  {KL}$ divergence as a function of $C$ (across the $50$ different values of $\theta $) and the bottom right plot shows the corresponding standard deviation. $50$ random seeds used for each clipping bound value with each random seed corresponding to a specific $\theta $ sampled from the prior distribution, $p(\theta ) = \altmathcal  {N}(0, 5)$ and specific draw of corrupting noise. $\sigma _e = 0.5$, $\sigma =5$, $\eta =0.1$ with $M=20$ workers and $10$ data-points per worker. \relax }}{26}{figure.caption.24}}
\newlabel{fig:results-local-ana}{{4.4}{26}{Results obtained with data-point level differential privacy with $\epsilon _{\text {max}} = 10$ (i.e. termination after $\epsilon $ exceeds this value). Top left plot shows ratio between the true precision and obtained precision as a function of $\theta $, averaged over the last ten iterations of the DP-PVI algorithm. Top right plot shows the $\altmathcal {KL}(q||p)$ (again averaged over the ten last iterations) as a function of $\theta $. Bottom left plots show the mean, median and chosen percentiles of this averaged $\altmathcal {KL}$ divergence as a function of $C$ (across the $50$ different values of $\theta $) and the bottom right plot shows the corresponding standard deviation. $50$ random seeds used for each clipping bound value with each random seed corresponding to a specific $\theta $ sampled from the prior distribution, $p(\theta ) = \altmathcal {N}(0, 5)$ and specific draw of corrupting noise. $\sigma _e = 0.5$, $\sigma =5$, $\eta =0.1$ with $M=20$ workers and $10$ data-points per worker. \relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces  Typical posteriors obtained using the data-point level DP-PVI algorithm with analytical clipped updates. Produced with $C=2$, $\eta =0.1$, $M=20$ workers with $10$ data-points per worker. \relax }}{27}{figure.caption.25}}
\newlabel{fig:results-local-ana-post}{{4.5}{27}{Typical posteriors obtained using the data-point level DP-PVI algorithm with analytical clipped updates. Produced with $C=2$, $\eta =0.1$, $M=20$ workers with $10$ data-points per worker. \relax }{figure.caption.25}{}}
\@LN{539}{30}
\@LN{540}{30}
\@LN{541}{30}
\@LN{542}{30}
\@LN{543}{30}
\@LN{544}{30}
\@LN{545}{30}
\@LN{546}{30}
\@LN{547}{30}
\@LN{548}{30}
\@LN{549}{30}
\@LN{550}{30}
\@LN{551}{30}
\@LN{552}{30}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!40}{\leavevmode {\color {green!40}o}}\ I could do the analytical maths for this and plot if, if I had time}{27}{section*.27}}
\@LN{553}{30}
\@LN{554}{30}
\@LN{555}{31}
\@LN{556}{31}
\@LN{557}{31}
\@LN{558}{31}
\@LN{559}{31}
\@LN{560}{31}
\@LN{561}{31}
\@LN{562}{31}
\@LN{563}{31}
\@LN{564}{31}
\@LN{565}{31}
\@LN{566}{31}
\@LN{567}{31}
\@LN{568}{31}
\@LN{569}{31}
\@LN{570}{31}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Hydrid Scheme}{28}{subsection.4.2.3}}
\@LN{571}{31}
\@LN{572}{31}
\@LN{573}{31}
\@LN{574}{31}
\@LN{575}{31}
\@LN{576}{31}
\@LN{577}{31}
\@LN{578}{31}
\@LN{579}{31}
\@LN{580}{31}
\@LN{581}{31}
\@LN{582}{31}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Dataset Level DP-PVI}{28}{section.4.3}}
\@LN{583}{31}
\@LN{584}{31}
\@LN{585}{31}
\@LN{586}{31}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces  Results obtained with data-point level differential privacy applied \textbf  {without noise} when run for the same number of iterations as Fig. \ref  {fig:results-local-ana}. Top left plot shows ratio between the true precision and obtained precision as a function of $\theta $, averaged over the last ten iterations of the DP-PVI algorithm. Top right plot shows the $\altmathcal  {KL}(q||p)$ (again averaged over the ten last iterations) as a function of $\theta $. Bottom left plots show the mean, median and chosen percentiles of this averaged $\altmathcal  {KL}$ divergence as a function of $C$ (across the $50$ different values of $\theta $) and the bottom right plot shows the corresponding standard deviation. $50$ random seeds used for each clipping bound value with each random seed corresponding to a specific $\theta $ sampled from the prior distribution, $p(\theta ) = \altmathcal  {N}(0, 5)$ and specific draw of corrupting noise. $\sigma _e = 0.5$, $\eta =0.1$ with $M=20$ workers and $10$ data-points per worker. \relax }}{29}{figure.caption.28}}
\newlabel{fig:results-noiseless-local-ana}{{4.6}{29}{Results obtained with data-point level differential privacy applied \textbf {without noise} when run for the same number of iterations as Fig. \ref {fig:results-local-ana}. Top left plot shows ratio between the true precision and obtained precision as a function of $\theta $, averaged over the last ten iterations of the DP-PVI algorithm. Top right plot shows the $\altmathcal {KL}(q||p)$ (again averaged over the ten last iterations) as a function of $\theta $. Bottom left plots show the mean, median and chosen percentiles of this averaged $\altmathcal {KL}$ divergence as a function of $C$ (across the $50$ different values of $\theta $) and the bottom right plot shows the corresponding standard deviation. $50$ random seeds used for each clipping bound value with each random seed corresponding to a specific $\theta $ sampled from the prior distribution, $p(\theta ) = \altmathcal {N}(0, 5)$ and specific draw of corrupting noise. $\sigma _e = 0.5$, $\eta =0.1$ with $M=20$ workers and $10$ data-points per worker. \relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces  Typical posteriors obtained using the \textbf  {noiseless} data-point level DP-PVI algorithm with analytical clipped updates. Produced with $C=2$, $\eta =0.1$, $M=20$ workers with $10$ data-points per worker.\relax }}{30}{figure.caption.29}}
\newlabel{fig:results-noiseless-typical-post}{{4.7}{30}{Typical posteriors obtained using the \textbf {noiseless} data-point level DP-PVI algorithm with analytical clipped updates. Produced with $C=2$, $\eta =0.1$, $M=20$ workers with $10$ data-points per worker.\relax }{figure.caption.29}{}}
\@setckpt{Results/results}{
\setcounter{page}{31}
\setcounter{equation}{24}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{3}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{7}
\setcounter{table}{0}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{linenumber}{587}
\setcounter{LN@truepage}{34}
\setcounter{parentequation}{0}
\setcounter{Item}{4}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{26}
\setcounter{ALG@line}{13}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{3}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{NAT@ctr}{0}
\setcounter{@todonotes@numberoftodonotes}{16}
\setcounter{currfiledepth}{0}
\setcounter{theorem}{0}
\setcounter{corollary}{0}
\setcounter{section@level}{1}
}
